"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[324],{5335:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module-4-vla-capstone/intro","title":"Introduction to Module 4: Voice-Language-Action (VLA) Pipeline","description":"Overview","source":"@site/docs/module-4-vla-capstone/intro.md","sourceDirName":"module-4-vla-capstone","slug":"/module-4-vla-capstone/intro","permalink":"/docs/module-4-vla-capstone/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla-capstone/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Navigation with Nav2","permalink":"/docs/module-3-isaac-sim/navigation-with-nav2"},"next":{"title":"Voice Processing and Speech Recognition","permalink":"/docs/module-4-vla-capstone/voice-processing"}}');var t=i(4848),s=i(8453);const r={sidebar_position:1},l="Introduction to Module 4: Voice-Language-Action (VLA) Pipeline",a={},c=[{value:"Overview",id:"overview",level:2},{value:"What You&#39;ll Learn",id:"what-youll-learn",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Module Structure",id:"module-structure",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"introduction-to-module-4-voice-language-action-vla-pipeline",children:"Introduction to Module 4: Voice-Language-Action (VLA) Pipeline"})}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"Welcome to Module 4 of the Physical AI & Humanoid Robotics book. In this final module, we'll explore Voice-Language-Action (VLA) frameworks that combine speech recognition, natural language processing, and robotic action execution. You'll learn to build systems that respond to voice commands, interpret natural language, and execute complex robotic behaviors."}),"\n",(0,t.jsx)(n.h2,{id:"what-youll-learn",children:"What You'll Learn"}),"\n",(0,t.jsx)(n.p,{children:"In this module, you will:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Implement voice processing pipelines using tools like Whisper"}),"\n",(0,t.jsx)(n.li,{children:"Integrate Large Language Models (LLMs) for natural language understanding"}),"\n",(0,t.jsx)(n.li,{children:"Create action mapping systems for robot execution"}),"\n",(0,t.jsx)(n.li,{children:"Design and implement complete VLA systems with safety considerations"}),"\n",(0,t.jsx)(n.li,{children:"Evaluate and improve VLA system performance"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsx)(n.p,{children:"Before starting this module, you should have:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Completed Modules 1-3 (ROS 2, simulation, Isaac ecosystem)"}),"\n",(0,t.jsx)(n.li,{children:"Basic understanding of machine learning concepts"}),"\n",(0,t.jsx)(n.li,{children:"Familiarity with API integration and web services"}),"\n",(0,t.jsx)(n.li,{children:"Understanding of safety considerations in robotics"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"module-structure",children:"Module Structure"}),"\n",(0,t.jsx)(n.p,{children:"This module is divided into several chapters that build upon each other:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Voice Processing"})," - Speech recognition and audio processing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Language Understanding"})," - LLM integration and natural language processing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Action Execution"})," - Mapping language to robot actions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Complete VLA System"})," - Integration and capstone project"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Let's begin building voice-controlled robotic systems!"})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>l});var o=i(6540);const t={},s=o.createContext(t);function r(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);